# Spark Configuration for US Accidents Lakehouse
# Based on analysis of existing applications

# Memory Configuration
spark.driver.memory                    4g
spark.executor.memory                  4g
spark.executor.cores                   2

# Adaptive Query Execution
spark.sql.adaptive.enabled             true
spark.sql.adaptive.coalescePartitions.enabled  true

# Arrow-based columnar data transfers
spark.sql.execution.arrow.pyspark.enabled      true

# Serialization
spark.serializer                       org.apache.spark.serializer.KryoSerializer

# Dynamic Allocation (optional)
spark.dynamicAllocation.enabled        false
spark.dynamicAllocation.minExecutors   1
spark.dynamicAllocation.maxExecutors   4

# Shuffle Configuration
spark.sql.shuffle.partitions           200
spark.sql.adaptive.shuffle.targetPostShuffleInputSize  64MB

# Parquet Configuration
spark.sql.parquet.compression.codec    snappy
spark.sql.parquet.enableVectorizedReader  true

# UI Configuration
spark.ui.enabled                       true
spark.ui.port                          4040

# Logging
spark.eventLog.enabled                 false

# Network timeout
spark.network.timeout                  300s
spark.sql.broadcastTimeout             300

# Memory fraction
spark.sql.execution.arrow.maxRecordsPerBatch  10000